{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b950d0",
   "metadata": {},
   "source": [
    "## 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import run_F4\n",
    "from Data.Data_Parser import fetch_all_dataset\n",
    "from Solution.Map_Printer import osm_print_cluster_tours, COLOR_LIST\n",
    "from Cluster_MILP import preprocess_clusters, calculate_arcs, fetch_arcs, cluster_MILP\n",
    "from cluster import kmeans, kmedoids, kmeans_DBSCAN, som_cluster, p_median, recenter_clusters, convert_cluster_centers\n",
    "from IPython.display import IFrame\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c515e",
   "metadata": {},
   "source": [
    "## Review input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47862a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"LA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488962fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result = p_median(data, V_c, 9, runtime_limit=1800, print_out=False)\n",
    "# cluster_result = kmeans(data) # new center\n",
    "# cluster_result = kmedoids(data, 10)\n",
    "# cluster_result = kmeans_DBSCAN(data) # new center\n",
    "\n",
    "# df = pd.read_csv(\".\\\\Data\\\\Shanghai.nodes\", sep='\\t')\n",
    "# cluster_result = som_cluster(df, map_shape=(3, 3), num_iteration=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008e82e",
   "metadata": {},
   "source": [
    "## 2. Traditional home delivery model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddbdf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_index = len(result_df)\n",
    "# input: 'Paris' for Paris dataset, 'Shanghai' for Shanghai dataset, and 'LA' for USA dataset\n",
    "data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "start_time = time.time()\n",
    "\n",
    "objective_value, solution, runtime, mip_gap = run_F4(\n",
    "    demands, vertices, arcs, V_d, V_c, F, alpha, K, Q,\n",
    "    runtime_limit=1800, gap_acceptance=0.01, print_out=True\n",
    ")\n",
    "\n",
    "result_dict = {\n",
    "    \"obj_value\": objective_value,\n",
    "    \"runtime\": runtime,\n",
    "    \"mip_gap\": mip_gap,\n",
    "    \"solution\": solution\n",
    "}\n",
    "# input: 'Paris' for Paris dataset, 'Shanghai' for Shanghai dataset, and 'LA' for USA dataset\n",
    "result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "result_df.loc[current_index, 'cluster_method'] = \"None\"\n",
    "result_df.loc[current_index, 'R'] = \"-\"\n",
    "result_df.loc[current_index, 'num_clusters'] = \"-\"\n",
    "result_df.loc[current_index, 'num_deli_nodes'] = len(V_c)\n",
    "result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "result_df.loc[current_index, 'avg_cluster_size'] = \"-\"\n",
    "result_df.loc[current_index, 'avg_cluster_cost'] = \"-\"\n",
    "result_df.loc[current_index, 'total_cost'] = result_dict['obj_value']\n",
    "result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "# input: 'Paris' for Paris dataset, 'Shanghai' for Shanghai dataset, and 'LA' for USA dataset\n",
    "result_df.to_csv(\"Paris_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442978de",
   "metadata": {},
   "source": [
    "## 3. Model with combination of packstations and customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f52d5",
   "metadata": {},
   "source": [
    "### Set  R and K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db54bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R_list = np.linspace(2.0, 5.0, num=7)\n",
    "R_list = np.array(range(2, 6))\n",
    "K_clusters = np.array(range(5, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3057e94",
   "metadata": {},
   "source": [
    "### Reset dataframe for the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3740fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fac9c6",
   "metadata": {},
   "source": [
    "### Clustering method: Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662904ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(R_list):\n",
    "    for j in tqdm(K_clusters):\n",
    "        current_index = len(result_df)\n",
    "        \n",
    "        data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        cluster_result = kmeans(data, j)\n",
    "        \n",
    "        result_dict, _vertices, _demands = cluster_MILP(\n",
    "            data, vertices, arcs, F, alpha, K, Q, demands, \n",
    "            cluster_result, i, runtime_limit=1800, gap_acceptance=0.01, print_out=False, fast_cal=False\n",
    "        )        \n",
    "\n",
    "        result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "        result_df.loc[current_index, 'cluster_method'] = \"Kmeans\"\n",
    "        result_df.loc[current_index, 'R'] = i\n",
    "        result_df.loc[current_index, 'num_clusters'] = j\n",
    "        result_df.loc[current_index, 'num_deli_nodes'] = len(_vertices) - 1\n",
    "        result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "        result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "        total_size = 0\n",
    "        total_cost = 0\n",
    "        for v in [v for v in _vertices if v.startswith('P')]:\n",
    "            total_cost += 8.3\n",
    "            if _demands.get(v) > 4000:\n",
    "                total_cost += (_demands.get(v) - 4000) * 0.002\n",
    "            total_size += _demands.get(v)\n",
    "        \n",
    "        result_df.loc[current_index, 'avg_cluster_size'] = total_size / j\n",
    "        result_df.loc[current_index, 'avg_cluster_cost'] = total_cost / j\n",
    "        result_df.loc[current_index, 'total_cost'] = total_cost + result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "        result_df.to_csv(\"Paris_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c4d860",
   "metadata": {},
   "source": [
    "### Clustering method: DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501d224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(R_list):\n",
    "#     if i == R_list[0]:\n",
    "#         continue\n",
    "    current_index = len(result_df)\n",
    "\n",
    "    data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    cluster_result = kmeans_DBSCAN(data)\n",
    "\n",
    "    result_dict, _vertices, _demands = cluster_MILP(\n",
    "        data, vertices, arcs, F, alpha, K, Q, demands, \n",
    "        cluster_result, i, runtime_limit=1800, gap_acceptance=0.01, print_out=False, fast_cal=False\n",
    "    )        \n",
    "\n",
    "    result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "    result_df.loc[current_index, 'cluster_method'] = \"kmeans_DBSCAN\"\n",
    "    result_df.loc[current_index, 'R'] = i\n",
    "    result_df.loc[current_index, 'num_clusters'] = len(cluster_result.items())\n",
    "    result_df.loc[current_index, 'num_deli_nodes'] = len(_vertices) - 1\n",
    "    result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "    result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "    result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "    total_size = 0\n",
    "    total_cost = 0\n",
    "    for v in [v for v in _vertices if v.startswith('P')]:\n",
    "        total_cost += 8.3\n",
    "        if _demands.get(v) > 4000:\n",
    "            total_cost += (_demands.get(v) - 4000) * 0.002\n",
    "        total_size += _demands.get(v)\n",
    "\n",
    "    result_df.loc[current_index, 'avg_cluster_size'] = total_size / len(cluster_result.items())\n",
    "    result_df.loc[current_index, 'avg_cluster_cost'] = total_cost / len(cluster_result.items())\n",
    "    result_df.loc[current_index, 'total_cost'] = total_cost + result_dict['obj_value']\n",
    "    result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "    result_df.to_csv(\"Paris_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b3278",
   "metadata": {},
   "source": [
    "### Clustering method: P median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f081c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(R_list):\n",
    "    for j in tqdm(K_clusters):\n",
    "        current_index = len(result_df)\n",
    "        \n",
    "        data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        cluster_result = p_median(data, V_c, j, runtime_limit=1800, print_out=False)\n",
    "        \n",
    "        result_dict, _vertices, _demands = cluster_MILP(\n",
    "            data, vertices, arcs, F, alpha, K, Q, demands, \n",
    "            cluster_result, i, runtime_limit=1800, gap_acceptance=0.01, print_out=False, fast_cal=False\n",
    "        )        \n",
    "\n",
    "        result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "        result_df.loc[current_index, 'cluster_method'] = \"p_median\"\n",
    "        result_df.loc[current_index, 'R'] = i\n",
    "        result_df.loc[current_index, 'num_clusters'] = j\n",
    "        result_df.loc[current_index, 'num_deli_nodes'] = len(_vertices) - 1\n",
    "        result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "        result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "        total_size = 0\n",
    "        total_cost = 0\n",
    "        for v in [v for v in _vertices if v.startswith('P')]:\n",
    "            total_cost += 8.3\n",
    "            if _demands.get(v) > 4000:\n",
    "                total_cost += (_demands.get(v) - 4000) * 0.002\n",
    "            total_size += _demands.get(v)\n",
    "        \n",
    "        result_df.loc[current_index, 'avg_cluster_size'] = total_size / j\n",
    "        result_df.loc[current_index, 'avg_cluster_cost'] = total_cost / j\n",
    "        result_df.loc[current_index, 'total_cost'] = total_cost + result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "        result_df.to_csv(\"Paris_Result_pmedian.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c3876",
   "metadata": {},
   "source": [
    "### Clustering method: Kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc7982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(R_list):\n",
    "    for j in tqdm(K_clusters):\n",
    "        current_index = len(result_df)\n",
    "        \n",
    "        data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        cluster_result = kmedoids(data, j)\n",
    "        \n",
    "        result_dict, _vertices, _demands = cluster_MILP(\n",
    "            data, vertices, arcs, F, alpha, K, Q, demands, \n",
    "            cluster_result, i, runtime_limit=1800, gap_acceptance=0.01, print_out=False, fast_cal=False\n",
    "        )        \n",
    "\n",
    "        result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "        result_df.loc[current_index, 'cluster_method'] = \"kmedoids\"\n",
    "        result_df.loc[current_index, 'R'] = i\n",
    "        result_df.loc[current_index, 'num_clusters'] = j\n",
    "        result_df.loc[current_index, 'num_deli_nodes'] = len(_vertices) - 1\n",
    "        result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "        result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "        total_size = 0\n",
    "        total_cost = 0\n",
    "        for v in [v for v in _vertices if v.startswith('P')]:\n",
    "            total_cost += 8.3\n",
    "            if _demands.get(v) > 4000:\n",
    "                total_cost += (_demands.get(v) - 4000) * 0.002\n",
    "            total_size += _demands.get(v)\n",
    "        \n",
    "        result_df.loc[current_index, 'avg_cluster_size'] = total_size / j\n",
    "        result_df.loc[current_index, 'avg_cluster_cost'] = total_cost / j\n",
    "        result_df.loc[current_index, 'total_cost'] = total_cost + result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "        result_df.to_csv(\"Paris_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7bec9",
   "metadata": {},
   "source": [
    "### Clustering method: SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b494e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_shape = [(1, 5), (2, 3), (1, 7), (2, 4), (3, 3), (2, 5)]\n",
    "\n",
    "for i in tqdm(R_list):\n",
    "    for j in tqdm(K_shape):\n",
    "        current_index = len(result_df)\n",
    "        if i == R_list[0] and j == K_shape[0]:\n",
    "            continue\n",
    "        \n",
    "        data, vertices, arcs, V_d, V_c, F, alpha, K, Q, demands = fetch_all_dataset(\"Paris\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        df = pd.read_csv(\".\\\\Data\\\\Paris.nodes\", sep=' ')\n",
    "        cluster_result = som_cluster(df, map_shape=j, num_iteration=100000)\n",
    "        \n",
    "        result_dict, _vertices, _demands = cluster_MILP(\n",
    "            data, vertices, arcs, F, alpha, K, Q, demands, \n",
    "            cluster_result, i, runtime_limit=1800, gap_acceptance=0.01, print_out=False, fast_cal=False\n",
    "        )        \n",
    "\n",
    "        result_df.loc[current_index, 'dataset'] = 'Paris'\n",
    "        result_df.loc[current_index, 'cluster_method'] = \"SOM\"\n",
    "        result_df.loc[current_index, 'R'] = i\n",
    "        result_df.loc[current_index, 'num_clusters'] = j[0] * j[1]\n",
    "        result_df.loc[current_index, 'num_deli_nodes'] = len(_vertices) - 1\n",
    "        result_df.loc[current_index, 'milp_obj'] = result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'milp_mip_gap'] = result_dict['mip_gap']\n",
    "        result_df.loc[current_index, 'milp_runtime'] = result_dict['runtime']\n",
    "\n",
    "        total_size = 0\n",
    "        total_cost = 0\n",
    "        for v in [v for v in _vertices if v.startswith('P')]:\n",
    "            total_cost += 8.3\n",
    "            if _demands.get(v) > 4000:\n",
    "                total_cost += (_demands.get(v) - 4000) * 0.002\n",
    "            total_size += _demands.get(v)\n",
    "        \n",
    "        result_df.loc[current_index, 'avg_cluster_size'] = total_size / (j[0] * j[1])\n",
    "        result_df.loc[current_index, 'avg_cluster_cost'] = total_cost / (j[0] * j[1])\n",
    "        result_df.loc[current_index, 'total_cost'] = total_cost + result_dict['obj_value']\n",
    "        result_df.loc[current_index, 'total_runtime'] = time.time() - start_time\n",
    "        result_df.to_csv(\"Paris_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185a52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
